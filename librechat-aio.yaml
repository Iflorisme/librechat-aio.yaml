# Configuration version (required)
version: 1.1.6

# Cache settings: Set to true to enable caching
cache: true

# Definition of custom endpoints
endpoints:
  custom:
    - name: "CablyAI"
      apiKey: "sk-LZIHSCWYSqqGUwgnE4qtmZPszDdgQH7D"
      baseURL: "https://cablyai.com/"
      models:
        default: [
          "openai/chatgpt-4o-latest",
          "openai/gpt-3.5-turbo",
          "openai/gpt-3.5-turbo-0125",
          "openai/gpt-3.5-turbo-0301",
          "openai/gpt-3.5-turbo-0613",
          "openai/gpt-3.5-turbo-1106",
          "openai/gpt-3.5-turbo-16k",
          "openai/gpt-3.5-turbo-instruct",
          "openai/gpt-4",
          "openai/gpt-4-0314",
          "openai/gpt-4-1106-preview",
          "openai/gpt-4-32k",
          "openai/gpt-4-32k-0314",
          "openai/gpt-4-turbo",
          "openai/gpt-4-turbo-preview",
          "openai/gpt-4-vision-preview",
          "openai/gpt-4o",
          "openai/gpt-4o-2024-05-13",
          "openai/gpt-4o-2024-08-06",
          "openai/gpt-4o-mini",
          "openai/gpt-4o-mini-2024-07-18",
          "openai/o1-mini",
          "openai/o1-mini-2024-09-12",
          "openai/o1-preview",
          "openai/o1-preview-2024-09-12"
        ]
        fetch: true
      titleConvo: true
      titleMethod: "completion"
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "CablyAI"

# See the Custom Configuration Guide for more information:
# https://docs.librechat.ai/install/configuration/custom_config.html
